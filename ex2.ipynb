{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starter file for extra credit homework EX2\n",
    "### enter you name and ID here:\n",
    "\n",
    "**name:**   \n",
    "\n",
    "**umbc username:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a stub for your notebook to use TensorFlow to train a simple feed-forward multi-layer perceptron neural netwrk using the big soo database of HW5.  You will have to preprocess the data to make it suitable for a MLP learner.  This can be done by changing the CSV file in your repository or in the TensorFlow note book or in a combination of both.\n",
    "\n",
    "When you have a working notbook, be sure to save it.  If you are running it on colab, you will have to dounload the notebook and then copy it into your repository.\n",
    "\n",
    "You can experiment with the notebook **ex2_wine_example.ipynb** which is in your repo. Step thought it, reading the comments and reviewing the output. To fully understand it, you may want to make some changes or add new cell to experiment with it. You can use this as a model to help you figure out how to complete this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVI7BWB56tUB"
   },
   "source": [
    "You can run this notebook on your local computer or on colab, but on colab, you must to an extra step of upload your file to colab.  It will only be there while your session on colab continues.  If you stop and return a few hours later, you will have to upload it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pW-Bdm83pXtF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJL0UT8I6tUE"
   },
   "source": [
    "### 1 Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtM8l2rG6tUF"
   },
   "source": [
    "We have to load the file slightly differently if we are running this on colab or our local computer. This will set the varialble **IN_COLAB** to True iff we are running on colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVy3ZLd06tUF"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running in colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKbWFTaX6tUE"
   },
   "source": [
    "This is the name of the file that has our data.  Edit it as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1zd6Ydj6tUF"
   },
   "outputs": [],
   "source": [
    "data_file_name = \"myzoo.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjv6yZIj6tUG"
   },
   "source": [
    "This will ask your to upload the file if you are using colab and requires navigating to and clicking on the file.  Note that the file will eventually be deleted from the colab server you are running on when your session ends. The session will end if you completely disconnect or are inactive for too long a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "p_g-HeoQ6tUG",
    "outputId": "aa0d11be-ea18-4d98-ba08-c45043906ba4"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    if os.path.exists(data_file_name):\n",
    "        print(\"Deleting prior version of\", data_file_name)\n",
    "        os.remove(data_file_name)\n",
    "    import io\n",
    "    from google.colab import files\n",
    "    print(\"When asked to select your file, find and click on\", data_file_name)\n",
    "    uploaded = files.upload()\n",
    "    the_file = io.BytesIO(uploaded[data_file_name])\n",
    "else:\n",
    "    the_file = data_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG-irywi6tUG"
   },
   "source": [
    "The numpy function [genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html) is any easy way to import data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-INEjeo6tUH",
    "outputId": "0cc4b070-59b8-4a3f-fcaa-6d70d2103f9f"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(the_file, delimiter=',')\n",
    "print(\"add expressions to print the data's shape and the first three rows of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQuKi89T6tUH"
   },
   "source": [
    "**X** will be the array minus the last column and **y** will be the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PAN95cB6tUI",
    "outputId": "c4be970b-5046-4b1d-c65f-875c95d984e8"
   },
   "outputs": [],
   "source": [
    "print(\"your code for extracting **X** and **y** from the numpy array **data**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ED3lwLqW6tUI"
   },
   "source": [
    "### 2 Preprocess the data\n",
    "\n",
    "We typically need to do some preprocessing of the data to make it work better with our machine learning system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_r5iHm4T6tUI",
    "outputId": "ccc2e695-2e2b-4e41-c181-74048747b4cb"
   },
   "outputs": [],
   "source": [
    "print(\"do any neccessary encoding here that  you've not done directly on the csv file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU8hK1Z76tUJ"
   },
   "source": [
    "We'll use the variables num_features and num_classes later when we define the TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rvw7qJ3RqcoQ",
    "outputId": "64b97a65-8a7c-4f38-e260-06ff669cb6ba"
   },
   "outputs": [],
   "source": [
    "# replace the pass expressions with expressions to get the right values from X and y\n",
    "num_features = pass\n",
    "num_classes = pass\n",
    "print(f\"num_features={num_features}; num_classes={num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjBBArFm6tUJ"
   },
   "source": [
    "Since the zoo dataset does not have floating point numbers for its features, we don't need to scale the values in X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDCoKdKl6tUJ"
   },
   "source": [
    "### 3 Build the model\n",
    "\n",
    "Using Keras makes constructing a neural network model easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPOEz0ak6tUK"
   },
   "source": [
    "TensofrFlow remembers the model parameter's weights if we run it repeateldly while debugging.  Calling the clear_session() function will reset the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASh9Ztiu6tUK"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UJ5Wael6tUK"
   },
   "source": [
    "You must choose how many layers to have and how big eacxh will be.  The first layer should note the expected input size as the number of features and the size of the last one should be the number of classes.   You'll have to experiment a bit to choose how many layers and what sizes they are.\n",
    "\n",
    "Calling model.summary will print a desciption of the model so we can confirm it looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0uIV94IS6tUK",
    "outputId": "cdc76ac4-7643-4db4-e2b0-f3538688b4d4"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # create layers for your model\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIxXJ4NK6tUL"
   },
   "source": [
    "### 4 Compile the Keras model into a neural network \n",
    "\n",
    "This step proruces the actual network structure and lets us specify addional parameters.  These are typical parameter values for optimiser and metrics.  The loss function *sparse_categorical_crossentropy* is one that's good for a multiclass problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1ynZQ6I6tUL",
    "outputId": "97cec52e-8797-4969-bdc0-f7a2ccc6ea6b"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"compiled, ready to train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6--ulsRC6tUL"
   },
   "source": [
    "### 5 Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDec8BGb6tUL"
   },
   "source": [
    "TensorFlow's callback mechansim lets us add several extras.  This [**EarlyStopping**](https://keras.io/api/callbacks/early_stopping/) callback will stop training when the loss on the validation data does not improve for some number of successive training epochs.  We will stop when the loss on the validation set stops improving (i.e., getting lower).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef0FxAK96tUL"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwJRbBkH6tUM"
   },
   "source": [
    "We train the model with a validation_split that holds out a fraction of the data as test data and captures the accuracy of the main training data and this validation data after each eopch.  Since this dataset is small, try starting with 0.1\n",
    "\n",
    "The fit( ) method returns a history object which records useful information about the model's training.  We'll examine it after we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvAYuXd-6tUM",
    "outputId": "c6245f48-ced8-42bd-e337-10c080bfa539"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_scaled, y, verbose=0, epochs=900, validation_split = 0.1, callbacks=[callback])\n",
    "print(f\"{len(history.history['loss'])} epochs run; final accuracy = {history.history['accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCmGEO336tUM"
   },
   "source": [
    "### 6 Review the results, draw conclusions, and make adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeT3t8886tUM"
   },
   "source": [
    "We plot the model accuracy and validation accuracy recorded in the history. **EarlyStopping** callback kicked in when the val_loss was not improving (i.e., getting lower) for several epochs.  This indicates that the model is beginning to overfit on the training data and it's time to stop training.\n",
    "\n",
    "While an accuracy does not sound impressive, it is about as good as one can get with this data using any machine learning method without overfitting.  If you edit this notebook to trai/n on X rather than X_scaled, the accuracy is significantly lower, about 0.46.\n",
    "\n",
    "We can plot the accuracy and validation accuracy for each epoch easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "xmWImnnM6tUN",
    "outputId": "9250f078-8ddd-4d10-a61e-2d18cbe421d3"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['accuracy','validation accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTvZFona6tUN"
   },
   "source": [
    "history is a dictionary that records values after each epoch.  Looking at its keys shows us the properties it records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "W0yLWujT6tUN",
    "outputId": "2ed9a9ef-6e38-4852-b27e-7392e7731e0b"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','validation loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlv9gLvc6tUN"
   },
   "source": [
    "fin"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ex2_wine_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
