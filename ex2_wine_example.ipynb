{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVI7BWB56tUB"
   },
   "source": [
    "### Example of a simple MLP in TensorFlow with Kreas using the [White wine quality dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality)\n",
    "\n",
    "This is one of two datasets from the UCI ML repository with data on red and white variants of the Portuguese \"Vinho Verde\" wine [Cortez et al., 2009]. They are appropriate for either classification or regression tasks. The classes are ordered, but not balanced, e.g., there are many more normal wines than excellent or poor ones. The eleven input variables are: 1 fixed acidity, 2 volatile acidity, 3 citric acid, 4 residual sugar, 5 chlorides, 6 free sulfur dioxide, 7 total sulfur dioxide, 8 density, 9 pH, 10 sulphates, 11 alcohol and the output variable is 12 quality (score between 0 and 10).\n",
    "\n",
    "You can run this notebook on your local computer or fro colab, but on colad, you must to an extra step of upload your file to colab.  It will only be there while your session on colab continues.  If you stop and com back a few hours later, you will have to upload it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pW-Bdm83pXtF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJL0UT8I6tUE"
   },
   "source": [
    "### 1 Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtM8l2rG6tUF"
   },
   "source": [
    "We have to load the file slightly differently if we are running this on colab or our local computer. This will set the varialble **IN_COLAB** to True iff we are running on colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVy3ZLd06tUF"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running in colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKbWFTaX6tUE"
   },
   "source": [
    "This is the name of the file that has our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1zd6Ydj6tUF"
   },
   "outputs": [],
   "source": [
    "data_file_name = \"winequality.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjv6yZIj6tUG"
   },
   "source": [
    "This will ask your to upload the file if you are using colab and requires navigating to and clicking on the file.  Note that the file will eventually be deleted from the colab server you are running on when your session ends. The session will end if you completely disconnect or are inactive for too long a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "p_g-HeoQ6tUG",
    "outputId": "aa0d11be-ea18-4d98-ba08-c45043906ba4"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    if os.path.exists(data_file_name):\n",
    "        print(\"Deleting prior version of\", data_file_name)\n",
    "        os.remove(data_file_name)\n",
    "    import io\n",
    "    from google.colab import files\n",
    "    print(\"When asked to select your file, find and click on\", data_file_name)\n",
    "    uploaded = files.upload()\n",
    "    the_file = io.BytesIO(uploaded[data_file_name])\n",
    "else:\n",
    "    the_file = data_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG-irywi6tUG"
   },
   "source": [
    "The numpy function [genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html) is any easy way to import data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-INEjeo6tUH",
    "outputId": "0cc4b070-59b8-4a3f-fcaa-6d70d2103f9f"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(the_file, delimiter=',')\n",
    "print(\"data.shape:\", data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQuKi89T6tUH"
   },
   "source": [
    "**X** will be the array minus the last column and **y** will be the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PAN95cB6tUI",
    "outputId": "c4be970b-5046-4b1d-c65f-875c95d984e8"
   },
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "print(f\"X.shape={X.shape} y.shape={y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ED3lwLqW6tUI"
   },
   "source": [
    "### 2 Preprocess the data\n",
    "\n",
    "We typically need to do some preprocessing of the data to make it work better with our machine learning system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQ1magdi6tUI"
   },
   "source": [
    "The unique y values are floating point versions of the integers between 3 and 7. TensorFlow will be happier if the y values are in {0,1,2,3,4,5,6}. sklearn's [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) does this easily by finding the unique values, sorting them, and replacing them with integers starting with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_r5iHm4T6tUI",
    "outputId": "ccc2e695-2e2b-4e41-c181-74048747b4cb"
   },
   "outputs": [],
   "source": [
    "print(f\"Initial unique y values = {np.unique(y)}\")\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "print(f\"After encoding, unique y values = {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU8hK1Z76tUJ"
   },
   "source": [
    "We'll use the variables num_features and num_classes later when we define the TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rvw7qJ3RqcoQ",
    "outputId": "64b97a65-8a7c-4f38-e260-06ff669cb6ba"
   },
   "outputs": [],
   "source": [
    "num_features = X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "print(f\"num_features={num_features}; num_classes={num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjBBArFm6tUJ"
   },
   "source": [
    "It's generally a good idea to scale the X columns, so let's use sklearn's [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to do this.  TensorFlow has scalers also, but the sklearn verison familiar and easy to use.  We print the first three rows of X before and after scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yk4EcU5n6tUJ",
    "outputId": "d78aa7db-5825-4932-b46a-629653021cac"
   },
   "outputs": [],
   "source": [
    "print(f\"Before scaling the input\\n{X[:3]}\")\n",
    "X_scaled = StandardScaler().fit(X).transform(X)\n",
    "print(f\"After scaling the input\\n{X_scaled[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDCoKdKl6tUJ"
   },
   "source": [
    "### 3 Build the model\n",
    "\n",
    "Using Keras makes constructing a neural network model easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPOEz0ak6tUK"
   },
   "source": [
    "TensofrFlow remembers the model parameter's weights if we run it repeateldly while debugging.  Calling the clear_session() function will reset the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASh9Ztiu6tUK"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UJ5Wael6tUK"
   },
   "source": [
    "Our model will have three dense layers of size 64, 64 and 32 followed by a final output layer with as many nodes as we have classes. The final layer will use the softmax activation rather than relu since the values it produces approximates the probability of correctness.\n",
    "\n",
    "Calling model.summary will print a desciption of the model so we can confirm it looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0uIV94IS6tUK",
    "outputId": "cdc76ac4-7643-4db4-e2b0-f3538688b4d4"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  layers.Dense(64, input_shape=(num_features,), activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIxXJ4NK6tUL"
   },
   "source": [
    "### 4 Compile the Keras model into a neural network \n",
    "\n",
    "This step proruces the actual network structure and lets us specify addional parameters.  These are typical parameter values for optimiser and metrics.  The loss function *sparse_categorical_crossentropy* is one that's good for a multiclass problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1ynZQ6I6tUL",
    "outputId": "97cec52e-8797-4969-bdc0-f7a2ccc6ea6b"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"compiled, ready to train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6--ulsRC6tUL"
   },
   "source": [
    "### 5 Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDec8BGb6tUL"
   },
   "source": [
    "TensorFlow's callback mechansim lets us add several extras.  This [**EarlyStopping**](https://keras.io/api/callbacks/early_stopping/) callback will stop training when the loss on the validation data does not improve for some number of successive training epochs.  We will stop when the loss on the validation set stops improving (i.e., getting lower).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef0FxAK96tUL"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwJRbBkH6tUM"
   },
   "source": [
    "We train the model with a validation_split that holds out a fraction of the data as test data and captures the accuracy of the main training data and this validation data after each eopch.\n",
    "\n",
    "The fit() method returns a history object which records useful information about the model's training.  We'll examine it aftr we train\n",
    "\n",
    "This will take 5-20 seconds to run, depending on your computer.  Wait for it to print the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvAYuXd-6tUM",
    "outputId": "c6245f48-ced8-42bd-e337-10c080bfa539"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_scaled, y, verbose=0, epochs=900, validation_split = 0.2, callbacks=[callback])\n",
    "print(f\"{len(history.history['loss'])} epochs run; final accuracy = {history.history['accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCmGEO336tUM"
   },
   "source": [
    "### 6 Review the results, draw conclusions, and make adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeT3t8886tUM"
   },
   "source": [
    "We plot the model accuracy and validation accuracy recorded in the history. **EarlyStopping** callback kicked in when the val_loss was not improving (i.e., getting lower) for several epochs.  This indicates that the model is beginning to overfit on the training data and it's time to stop training.\n",
    "\n",
    "While an accuracy does not sound impressive, it is about as good as one can get with this data using any machine learning method without overfitting.  If you edit this notebook to trai/n on X rather than X_scaled, the accuracy is significantly lower, about 0.46.\n",
    "\n",
    "We can plot the accuracy and validation accuracy for each epoch easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "xmWImnnM6tUN",
    "outputId": "9250f078-8ddd-4d10-a61e-2d18cbe421d3"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['accuracy','validation accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTvZFona6tUN"
   },
   "source": [
    "history is a dictionary that records values after each epoch.  Looking at its keys shows us the properties it records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fualul-N6tUN",
    "outputId": "3aa61323-8d55-4ee1-afa4-1e2bf0e19c78"
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2byHEUk6tUN"
   },
   "source": [
    "Ploting the loss and validation loss is also informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "W0yLWujT6tUN",
    "outputId": "2ed9a9ef-6e38-4852-b27e-7392e7731e0b"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','validation loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlv9gLvc6tUN"
   },
   "source": [
    "fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Bv85BQu6tUO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ex2_wine_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
